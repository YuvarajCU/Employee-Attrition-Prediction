{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KIK11cI-VslF",
        "yjtn6j5Np9uO",
        "ruHdzUrd2Du0",
        "9SNEiROV95CX",
        "oLzVrO357fwE",
        "F68mFNrf7rcN",
        "QdUxLfdOC1Ao",
        "uAbm7Ei8M0eO",
        "CTXBL3WYO0qE",
        "tshiWghFO3w_",
        "NDe3lH3sQpPZ",
        "87W84HH0RrFq",
        "jDguK6q7SydB",
        "jVxXf_WHTfax",
        "rtiRRqDFWKYd"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuvarajCU/Employee-Attrition-Prediction/blob/main/Employee_Attrition_Prediciton_Using_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Employee Attrition Prediction:**\n",
        "In the current era, companies are rapidly growing and seeking highly experienced professionals to meet their demands. Such experienced individuals are considered valuable assets to the company, and losing them can be costly. Companies may try to retain these employees by offering them better compensation, or they may choose to hire new employees altogether. Accurately predicting employee turnover can save companies significant amounts of money and time. Furthermore, it can help management control project pipelines more effectively, enabling them to manage their workforce in a flexible manner.\n",
        "\n",
        "# What is Attrition?\n",
        "\n",
        "When an employee moves out of the company either voluntarily or involuntarily, it is known as attrition. The attrition rate is calculated as the percent of employees who have left the organization by the average number of employees.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Attrition Rate = ((Number of employees who left during a given time period) / (Average total number of employees during the same time period)) x 100\n",
        "```\n",
        "\n",
        "The ideal employee attrition rate should be below 10%, while a rate exceeding 20% is concerning for any company. High attrition rates may be due to various reasons, such as poor management, lack of recognition, toxic work environment, and limited career growth opportunities. As we delve deeper into the data, we may discover additional factors contributing to attrition. In this blog, we aim to build an attrition prediction model that can forecast employees' likelihood to leave the organization in the future. Additionally, we will provide insights and feedback to the HR and talent acquisition departments, which can assist in reducing attrition rates in some areas. Let's begin by analyzing the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "27BTY70a4YJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Analysis\n",
        "\n",
        "Our objective is to investigate the interesting trends that result in employee turnover. Once the analysis is complete, we aim to build a machine learning model that predicts the likelihood of employees leaving the company."
      ],
      "metadata": {
        "id": "7ckP55PvVxSl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wkq3BdrzKLdl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_columns\", 100)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import datasets\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To upload the data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MvSXARY3dfMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/Hero Vired/Employee Atrrition Prediction/Dataset/general_data.csv'\n",
        "df=pd.read_csv(path)\n",
        "df1=pd.read_csv('/content/drive/MyDrive/Hero Vired/Employee Atrrition Prediction/Dataset/employee_survey_data.csv')\n",
        "df2=pd.read_csv('/content/drive/MyDrive/Hero Vired/Employee Atrrition Prediction/Dataset/manager_survey_data.csv')\n",
        "df = pd.merge(df, df1, on='EmployeeID', how='left')\n",
        "df = pd.merge(df, df2, on='EmployeeID', how='left')"
      ],
      "metadata": {
        "id": "e7ntBC3eK2dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Health Review"
      ],
      "metadata": {
        "id": "KIK11cI-VslF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "v0WyauY_Pant"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "5NN9oAOlPcm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df.isnull().mean()*100).sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "7TCguaxel7hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna(df.select_dtypes(include='number').mean())"
      ],
      "metadata": {
        "id": "fOE5pLbFTFda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df.isnull().mean()*100).sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "vvXmYH1bPgA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['NumCompaniesWorked'] = df['NumCompaniesWorked'].astype(int)\n",
        "df['TotalWorkingYears'] = df['TotalWorkingYears'].astype(int)\n",
        "df['EnvironmentSatisfaction'] = df['EnvironmentSatisfaction'].astype(int)\n",
        "df['JobSatisfaction'] = df['JobSatisfaction'].astype(int)\n",
        "df['WorkLifeBalance'] = df['WorkLifeBalance'].astype(int)"
      ],
      "metadata": {
        "id": "Yu0tAdK-mU4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "O9NcWRjincGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "At7HoKLIUVMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['EmployeeCount','EmployeeID','Over18','StandardHours'],inplace=True)"
      ],
      "metadata": {
        "id": "toYzV_wqUgYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col = df.columns\n",
        "for i in col:\n",
        "  print(i, 'percent :' , (len(df[i].unique())/len(df[i])) * 100, df[i].nunique())"
      ],
      "metadata": {
        "id": "SMojYekwhVLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "n7XAIg_HVBNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have made some checks on the data and made certain changes to our data set:\n",
        "1. We have found that there are few variables like the ratings which have some missing values and assuming those are supposed to be 0 instead, the missing values are replaced with zeros.\n",
        "2. Few variables in their float type are int type for the ease of analysis.\n",
        "3. We have dropped the Variables with either only one class('EmployeeCount','Over18','StandardHours) or being extremely high cardinal('EmployeeID').\n",
        "4. The 'Attrition' feature will be our dependent feature, and the rest of the features are independent.\n",
        "\n",
        "Let's visualize the histograms:"
      ],
      "metadata": {
        "id": "Nryq1ocr7SKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Histographs"
      ],
      "metadata": {
        "id": "yjtn6j5Np9uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(figsize=(15,15))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ciFyJyeepK5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Most distributions are right-skewed (Monthly Income, Total Working Years, Year at Company, Distance From Home, etc.).\n",
        "*   They are also tail heavy (Tails are not exponentially bounded).  \n",
        "*   The age feature is a little right-skewed, and most of the employees have ages between 25–40 years.\n",
        "\n",
        "*   These dataset are natural and most these are meant to be skewed and this may not affect the prediction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KYHIvvqDsZnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bivariant Analysis"
      ],
      "metadata": {
        "id": "nfUUfxuyC8kT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### personal data vs Attrition"
      ],
      "metadata": {
        "id": "9SNEiROV95CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(df.loc[df['Attrition']=='No','Age'],label='Active Employee')\n",
        "sns.kdeplot(df.loc[df['Attrition']=='Yes','Age'],label='Ex-Employee')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='Gender', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.countplot(x='DistanceFromHome', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='MaritalStatus', hue='Attrition',data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZmyqY99NVIbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Survey data vs Attrition"
      ],
      "metadata": {
        "id": "oLzVrO357fwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count plots Survey data vs Attrition\n",
        "\n",
        "sns.countplot(x='EnvironmentSatisfaction', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='JobSatisfaction', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='WorkLifeBalance', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "df['OverallEmployeeRating']=df[['EnvironmentSatisfaction','JobSatisfaction','WorkLifeBalance']].mean(axis=1).round()\n",
        "sns.countplot(x='OverallEmployeeRating', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='JobInvolvement', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='PerformanceRating', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "df['OverallManagerRating']=df[['JobInvolvement','PerformanceRating']].mean(axis=1).round()\n",
        "sns.countplot(x='OverallManagerRating', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "m4Q-yIxWDGZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Career info vs Attrition"
      ],
      "metadata": {
        "id": "F68mFNrf7rcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='Department', hue='Attrition',data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='Education', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.countplot(x='EducationField', hue='Attrition',data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='JobLevel', hue='Attrition',data=df)\n",
        "plt.show()\n",
        "\n",
        "ax=sns.countplot(x='JobRole', hue='Attrition',data=df)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x=\"BusinessTravel\", hue=\"Attrition\", data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.violinplot(x='MonthlyIncome',y='Attrition',data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='NumCompaniesWorked', hue='Attrition',data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='PercentSalaryHike', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.countplot(x='TotalWorkingYears', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='TrainingTimesLastYear', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.countplot(x='YearsAtCompany', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='YearsSinceLastPromotion', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='YearsWithCurrManager', hue='Attrition', data=df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='StockOptionLevel', hue='Attrition', data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3M1-ZbQsDQ2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "chkEEwoJ-aay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trivariant Analysis"
      ],
      "metadata": {
        "id": "QdUxLfdOC1Ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis on Job Role and Monthly Income"
      ],
      "metadata": {
        "id": "H04eS9Re2Mks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "ax=sns.boxplot(y=df[\"MonthlyIncome\"],x=df['JobRole'],hue=df[\"Attrition\"])\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
        "\n",
        "plt.grid(True, alpha=1)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q67DUzBMq5Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x=\"Gender\", hue=\"Attrition\", col=\"MaritalStatus\",\n",
        "            data=df, kind=\"count\", height=4, aspect=.7)"
      ],
      "metadata": {
        "id": "_69-t6yLBaSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary on the Data Analysis:\n",
        "\n",
        "1. Ex-employees have an average age of 33.6 years, while the current employees have 37.5 years.\n",
        "\n",
        "2. A younger employee is more likely to leave a company, and the education and marital status parameters are potential support.  \n",
        "3. Employees with Marital status- Single tend to have left the company compared to other two classes.\n",
        "3. MonthlyIncome doesnt seem to make any impact on the attrition rate, which can also negatively contribute for employees in bigger role.\n",
        "3. Lower stock option levels presented comparitively higher attritions\n",
        "4. Surveys aren't giving a clear picture, yet in terms of percentage, low ratings are being directly proportional to the attrition rate percentage of a class, but we cant rely on this analysis.\n",
        "5. Delay in Promotion saturates the interest of the employees\n",
        "6. Number of Employees in a particular Domain and job role has been directly proportional to attrition, probably due to the competitive population."
      ],
      "metadata": {
        "id": "V3uZ8pxqCW5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n",
        "\n",
        "Since the number of unique values in all categorical variables is less than 10, we will manually map them for sake of not producing anymore features and burder the model."
      ],
      "metadata": {
        "id": "uAbm7Ei8M0eO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Attrition"
      ],
      "metadata": {
        "id": "CTXBL3WYO0qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_dict = {'Yes': 1, 'No': 0}\n",
        "df['Attrition_New'] = df['Attrition'].map(map_dict)\n",
        "df['Attrition_New'].unique()"
      ],
      "metadata": {
        "id": "7KM62xB9TDWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Business Travel"
      ],
      "metadata": {
        "id": "tshiWghFO3w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BusinessTravel_dict = df[\"BusinessTravel\"].value_counts()\n",
        "print(BusinessTravel_dict)"
      ],
      "metadata": {
        "id": "rkSb9ZgFM3tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BusinessTravel_dict_new = {\n",
        "    'Travel_Rarely':     0,\n",
        "    'Travel_Frequently': 1,\n",
        "    'Non-Travel':        2,\n",
        "}\n",
        "print(BusinessTravel_dict_new)"
      ],
      "metadata": {
        "id": "YXRMvcksO7m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BusinessTravel(x):\n",
        "    if str(x) in BusinessTravel_dict_new.keys():\n",
        "        return BusinessTravel_dict_new[str(x)]\n",
        "df['New BusinessTravel'] = df[\"BusinessTravel\"].apply(BusinessTravel)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "LDW8e_utPT4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Department"
      ],
      "metadata": {
        "id": "NDe3lH3sQpPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Department_dict = df[\"Department\"].value_counts()\n",
        "print(Department_dict)"
      ],
      "metadata": {
        "id": "PAEtthoGQrmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Department_dict_new = {\n",
        "    'Research & Development': 0,\n",
        "    'Sales':                  1,\n",
        "    'Human Resources':        2,\n",
        "}\n",
        "print(Department_dict_new)"
      ],
      "metadata": {
        "id": "N-4ArSU8Q1nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Department(x):\n",
        "    if str(x) in Department_dict_new.keys():\n",
        "        return Department_dict_new[str(x)]\n",
        "df['New Department'] = df[\"Department\"].apply(Department)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "JDPVZAT0RQRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Education Field"
      ],
      "metadata": {
        "id": "87W84HH0RrFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EducationField_dict = df[\"EducationField\"].value_counts()\n",
        "print(EducationField_dict)"
      ],
      "metadata": {
        "id": "r1-ArcOKRtLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EducationField_dict_new = {\n",
        "    'Life Sciences':    0,\n",
        "    'Medical':          1,\n",
        "    'Marketing':        2,\n",
        "    'Technical Degree': 3,\n",
        "    'Other' :           4,\n",
        "    'Human Resources':  5\n",
        "\n",
        "}\n",
        "print(EducationField_dict_new)"
      ],
      "metadata": {
        "id": "l-VMefNPR2i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EducationField(x):\n",
        "    if str(x) in EducationField_dict_new.keys():\n",
        "        return EducationField_dict_new[str(x)]\n",
        "df['New EducationField'] = df[\"EducationField\"].apply(EducationField)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "VeRDH5rJSTkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gender"
      ],
      "metadata": {
        "id": "jDguK6q7SydB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_dict = {'Male': 0, 'Female': 1}\n",
        "df['Gender_new'] = df['Gender'].map(map_dict)\n",
        "df['Gender_new'].unique()"
      ],
      "metadata": {
        "id": "AXXCs-IJS5OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Job Role"
      ],
      "metadata": {
        "id": "jVxXf_WHTfax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JobRole_dict = df[\"JobRole\"].value_counts()\n",
        "print(JobRole_dict)"
      ],
      "metadata": {
        "id": "IIUEFzM-TfCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "JobRole_dict_new = {\n",
        "    'Sales Executive':            0,\n",
        "    'Research Scientist':         1,\n",
        "    'Laboratory Technician':      2,\n",
        "    'Manufacturing Director':     3,\n",
        "    'Healthcare Representative' : 4,\n",
        "    'Sales Representative':       5,\n",
        "    'Research Director':          6,\n",
        "    'Human Resources':            7,\n",
        "    'Manager':                    8\n",
        "\n",
        "}\n",
        "print(JobRole_dict_new)"
      ],
      "metadata": {
        "id": "v11vCZ1mTmp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def JobRole(x):\n",
        "    if str(x) in JobRole_dict_new.keys():\n",
        "        return JobRole_dict_new[str(x)]\n",
        "df['New JobRole'] = df[\"JobRole\"].apply(JobRole)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "ltVSPuIMUHU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Marital Status"
      ],
      "metadata": {
        "id": "rtiRRqDFWKYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MaritalStatus_dict = df[\"MaritalStatus\"].value_counts()\n",
        "print(MaritalStatus_dict)"
      ],
      "metadata": {
        "id": "WKe_qZUxWJyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MaritalStatus_dict_new = {\n",
        "    'Married':  0,\n",
        "    'Single':   1,\n",
        "    'Divorced': 2\n",
        "}\n",
        "print(MaritalStatus_dict_new)"
      ],
      "metadata": {
        "id": "5fmjeCxeWVNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MaritalStatus(x):\n",
        "    if str(x) in MaritalStatus_dict_new.keys():\n",
        "        return MaritalStatus_dict_new[str(x)]\n",
        "df['New MaritalStatus'] = df[\"MaritalStatus\"].apply(MaritalStatus)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "ALBoxrOwWlFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(df.select_dtypes('object'), axis=1)"
      ],
      "metadata": {
        "id": "8ibl4QzUgXfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Building"
      ],
      "metadata": {
        "id": "htmUdteDHhcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "Si8ehyKRIbpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation and OLS"
      ],
      "metadata": {
        "id": "UduXxWeYFWsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df.corr()\n",
        "print(corr)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "colormap = sns.color_palette(\"YlGnBu\")\n",
        "sns.heatmap(df.corr(), annot=True, cmap=colormap).set_title('Correlation Heatmap', fontdict={'fontsize':14})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OLt1rDHcHqdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_attrition = df.corr()['Attrition_New']\n",
        "print(corr_attrition.sort_values(ascending=True))"
      ],
      "metadata": {
        "id": "OfMLXwIkiK2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On comparison, the target variable (Attrition) has a negative correlation with Total Working Years, Age, Years With Current Manager, Overall Employee rating, Years at Company, Environment Satisfaction, Job Satisfaction, and Work Life balance. On the other hand, there are comparitively fewer variables that have a positive correlation with attrition, such as Department, Number of companies worked before, Percentage of salary hikes, and a few others.\n",
        "\n",
        "However, this doesn't mean that these features are not significant. Even a little distinction might help classify the attrition, so removing any of the attributes from the analysis is not recommended."
      ],
      "metadata": {
        "id": "8KXkgzp0hqgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Attrition_New'], axis=1)\n",
        "y = df['Attrition_New']\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "model = sm.Logit(y, X)\n",
        "result = model.fit()\n",
        "print(result.summary())\n",
        "\n",
        "p_values = result.pvalues\n",
        "print(p_values.sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "DtmCb1iPflgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 1: Normal Logistic Regression"
      ],
      "metadata": {
        "id": "Q236EoXISJrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "X = df.drop(columns=['Attrition_New'],axis=1)\n",
        "y = df['Attrition_New']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "print(recall_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "print(f1_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "print(classification_report(y_test, y_pred, zero_division=1))\n"
      ],
      "metadata": {
        "id": "6rwJkdAaFnGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: w/o Monthly Income"
      ],
      "metadata": {
        "id": "F5c-NedETZ-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "X = df.drop(columns=['Attrition_New','MonthlyIncome'],axis=1)\n",
        "y = df['Attrition_New']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "print(recall_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "print(f1_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "print(classification_report(y_test, y_pred, zero_division=1))"
      ],
      "metadata": {
        "id": "XQG5fa-diNu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 : Using RFE"
      ],
      "metadata": {
        "id": "D-F1FhErVFPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "X = df.drop(columns=['Attrition_New'],axis=1)\n",
        "y = df['Attrition_New']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "rfe = RFE(lr, n_features_to_select=20)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "X_train_selected = rfe.transform(X_train)\n",
        "X_test_selected = rfe.transform(X_test)\n",
        "\n",
        "lr.fit(X_train_selected, y_train)\n",
        "y_pred = lr.predict(X_test_selected)\n",
        "\n",
        "print(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "print(recall_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "print(f1_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "print(classification_report(y_test, y_pred, zero_division=1))\n"
      ],
      "metadata": {
        "id": "k5K49cmCcENW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models Using RFE and 3 differet Sampling techniques"
      ],
      "metadata": {
        "id": "ZnSi4kQSVMoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the feature and target variables\n",
        "X = df.drop(columns=['Attrition_New'],axis=1)\n",
        "y = df['Attrition_New']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the logistic regression model\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "\n",
        "rfe = RFE(lr, n_features_to_select=10)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "X_train_selected = rfe.transform(X_train)\n",
        "X_test_selected = rfe.transform(X_test)\n",
        "\n",
        "# Define the sampling methods\n",
        "over_sampler = RandomOverSampler(sampling_strategy='minority')\n",
        "under_sampler = RandomUnderSampler(sampling_strategy='majority')\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Apply the sampling methods to the training data\n",
        "X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n",
        "X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X, y)\n",
        "\n",
        "# Train and test the logistic regression model with each sampling method\n",
        "for X_train_resampled, y_train_resampled in [(X_train, y_train), (X_train_over, y_train_over),\n",
        "                                             (X_train_under, y_train_under), (X_train_smote, y_train_smote)]:\n",
        "    lr_model.fit(X_train_resampled, y_train_resampled)\n",
        "    y_pred = lr_model.predict(X_test)\n",
        "    print(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "    print(recall_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "    print(f1_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "\n",
        "    print('Classification report for resampled data:')\n",
        "    print(classification_report(y_test, y_pred, zero_division=1))\n",
        "\n",
        "    importances = pd.DataFrame({'feature': X_train.columns,'importance': np.abs(lr_model.coef_[0])})\n",
        "    importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
        "    print(importances)"
      ],
      "metadata": {
        "id": "h0yMY9RXwCZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Using SMOTE and Grid Search"
      ],
      "metadata": {
        "id": "735amkjqXfKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "X = df.drop(columns=['Attrition_New'], axis=1)\n",
        "y = df['Attrition_New']\n",
        "\n",
        "# Resample using SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
        "\n",
        "# Data Normalization\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'solver': ['lbfgs', 'liblinear', 'sag']}\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(LogisticRegression(), params, scoring='roc_auc', cv=10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Performing Parameter\n",
        "print('=' * 20)\n",
        "print(\"best params: \" + str(grid_search.best_estimator_))\n",
        "print(\"best params: \" + str(grid_search.best_params_))\n",
        "print('best score:', grid_search.best_score_)\n",
        "print('=' * 20)\n",
        "\n",
        "# Fit logistic regression model using best hyperparameters\n",
        "lr = LogisticRegression(C=grid_search.best_params_['C'], solver=grid_search.best_params_['solver'])\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "1J1hjBqK434x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 using Grid Search"
      ],
      "metadata": {
        "id": "0xF_KWxcXq9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing some observations whose class is in majority\n",
        "# This is an important step to balance the dataset\n",
        "df = df[(df['Attrition_New'] != 0) | (np.random.rand(len(df)) < .33)]\n",
        "\n",
        "X = df.drop(columns=['Attrition_New'], axis=1)\n",
        "y = df['Attrition_New']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
        "\n",
        "# Data Normalization\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Defining parameters for hyper-parameter tuning\n",
        "params = {'solver': ['newton-cg', 'liblinear'],\n",
        "          'penalty': ['l2'],\n",
        "          'C': np.logspace(-4.5, 4.5, 50),\n",
        "          'class_weight': ['balanced'],\n",
        "          'max_iter': [1000, 5000, 10000],\n",
        "          'tol': [0.0001, 0.001, 0.01, 0.1],\n",
        "          'fit_intercept': [True, False],\n",
        "          'intercept_scaling': [1, 2, 3]}\n",
        "\n",
        "# Initializing Grid Search with Logistic Regression and keeping roc_auc as the performance metrics!\n",
        "grid_search = GridSearchCV(estimator=LogisticRegression(),\n",
        "                           param_grid=params,\n",
        "                           cv=10,\n",
        "                           n_jobs=-1,\n",
        "                           verbose=0,\n",
        "                           scoring=\"roc_auc\",\n",
        "                           return_train_score=True)\n",
        "\n",
        "# Training\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Performing Parameter\n",
        "print('=' * 20)\n",
        "print(\"best params: \" + str(grid_search.best_estimator_))\n",
        "print(\"best params: \" + str(grid_search.best_params_))\n",
        "print('best score:', grid_search.best_score_)\n",
        "print('=' * 20)"
      ],
      "metadata": {
        "id": "aToX79HRik85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 Using Grid Search"
      ],
      "metadata": {
        "id": "x9qWTv0OYrIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing some observations whose class is in majority\n",
        "# This is an important step to balance the dataset\n",
        "df = df[(df['Attrition_New'] != 0) | (np.random.rand(len(df)) < .33)]\n",
        "\n",
        "X = df.drop(columns=['Attrition_New'], axis=1)\n",
        "y = df['Attrition_New']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
        "\n",
        "# Data Normalization\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Defining parameters for hyper-parameter tuning\n",
        "params = {'solver': ['newton-cg','lbfgs'],\n",
        "          'penalty': ['l2'],\n",
        "          'C': np.logspace(-4.5, 4.5, 50),\n",
        "          'class_weight': ['balanced'],\n",
        "          'max_iter': [1000, 5000, 10000],\n",
        "          'tol': [0.0001, 0.001, 0.01, 0.1],\n",
        "          'fit_intercept': [True, False],\n",
        "          'intercept_scaling': [1, 2, 3]}\n",
        "\n",
        "# Initializing Grid Search with Logistic Regression and keeping roc_auc as the performance metrics!\n",
        "grid_search = GridSearchCV(estimator=LogisticRegression(),\n",
        "                           param_grid=params,\n",
        "                           cv=10,\n",
        "                           n_jobs=-1,\n",
        "                           verbose=0,\n",
        "                           scoring=\"roc_auc\",\n",
        "                           return_train_score=True)\n",
        "\n",
        "# Training\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Performing Parameter\n",
        "print('=' * 20)\n",
        "print(\"best params: \" + str(grid_search.best_estimator_))\n",
        "print(\"best params: \" + str(grid_search.best_params_))\n",
        "print('best score:', grid_search.best_score_)\n",
        "print('=' * 20)"
      ],
      "metadata": {
        "id": "imyxa2EXOlA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 Using Grid Search"
      ],
      "metadata": {
        "id": "MLwpCiCeX3Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing some observations whose class is in majority\n",
        "# This is an important step to balance the dataset\n",
        "df = df[(df['Attrition_New'] != 0) | (np.random.rand(len(df)) < .33)]\n",
        "\n",
        "X = df.drop(columns=['Attrition_New'], axis=1)\n",
        "y = df['Attrition_New']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
        "\n",
        "# Data Normalization\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Defining parameters for hyper-parameter tuning\n",
        "params = {'solver': ['newton-cg', 'liblinear'],\n",
        "          'penalty': ['l2'],\n",
        "          'C': np.logspace(-4.5, 4.5, 50),\n",
        "          'class_weight': ['balanced'],\n",
        "          'max_iter': [1000, 5000, 10000],\n",
        "          'tol': [0.0001, 0.001, 0.01, 0.1],\n",
        "          'fit_intercept': [True, False],\n",
        "          'intercept_scaling': [1, 2, 3]}\n",
        "\n",
        "# Initializing Grid Search with Logistic Regression and keeping roc_auc as the performance metrics!\n",
        "grid_search = GridSearchCV(estimator=LogisticRegression(),\n",
        "                           param_grid=params,\n",
        "                           cv=10,\n",
        "                           n_jobs=-1,\n",
        "                           verbose=0,\n",
        "                           scoring=\"roc_auc\",\n",
        "                           return_train_score=True)\n",
        "\n",
        "# Training\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Performing Parameter\n",
        "print('=' * 20)\n",
        "print(\"best params: \" + str(grid_search.best_estimator_))\n",
        "print(\"best params: \" + str(grid_search.best_params_))\n",
        "print('best score:', grid_search.best_score_)\n",
        "print('=' * 20)"
      ],
      "metadata": {
        "id": "y9M5d4RkYpHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing some observations whose class is in majority\n",
        "# This is an important step to balance the dataset\n",
        "df = df[(df['Attrition_New'] != 0) | (np.random.rand(len(df)) < .33)]\n",
        "\n",
        "X = df.drop(columns=['Attrition_New'], axis=1)\n",
        "y = df['Attrition_New']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
        "\n",
        "# Data Normalization\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Defining parameters for hyper-parameter tuning\n",
        "params = {'solver': ['newton-cg'],\n",
        "          'penalty': ['l2'],\n",
        "          'C': np.logspace(-4.5, 4.5, 50),\n",
        "          'class_weight': ['balanced'],\n",
        "          'max_iter': [1000, 5000, 10000],\n",
        "          'tol': [0.0001, 0.001, 0.01, 0.1],\n",
        "          'fit_intercept': [True, False],\n",
        "          'intercept_scaling': [1, 2, 3]}\n",
        "\n",
        "# Initializing Grid Search with Logistic Regression and keeping roc_auc as the performance metrics!\n",
        "grid_search = GridSearchCV(estimator=LogisticRegression(),\n",
        "                           param_grid=params,\n",
        "                           cv=10,\n",
        "                           n_jobs=-1,\n",
        "                           verbose=0,\n",
        "                           scoring=\"roc_auc\",\n",
        "                           return_train_score=True)\n",
        "\n",
        "# Training\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Performing Parameter\n",
        "print('=' * 20)\n",
        "print(\"best params: \" + str(grid_search.best_estimator_))\n",
        "print(\"best params: \" + str(grid_search.best_params_))\n",
        "print('best score:', grid_search.best_score_)\n",
        "print('=' * 20)"
      ],
      "metadata": {
        "id": "TDWD0PRzZe7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plot-metric"
      ],
      "metadata": {
        "id": "jSZfbmPc84VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's evaluate the performance of the model over the testing dataset:\n",
        "from plot_metric.functions import BinaryClassification as BC\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "bc = BC(y_test, y_pred,labels=[0,1])\n",
        "\n",
        "# Plotting AUC_ROC Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "bc.plot_roc_curve()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zmIjfuKpufCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "print(\"The accuracy is {:.2f}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(\"The balanced accuracy is {:.2f}\".format(balanced_accuracy_score(y_test, y_pred)))\n",
        "print(\"The recall is {:.2f}\".format(recall_score(y_test, y_pred)))\n",
        "print(\"The precision is {:.2f}\".format(precision_score(y_test, y_pred)))\n",
        "print(\"The F1 Score is {:.2f}\".format(f1_score(y_test, y_pred)))\n",
        "print(\"The AUC ROC Score is {:.2f}\".format(roc_auc_score(y_test, y_pred)))\n",
        "\n",
        "cm = confusion_matrix(y_test, best_model.predict(X_test))\n",
        "classes = ['Not_Attrition', 'Attrition']\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 7))\n",
        "plt.title(\"Confusion Matrix\")\n",
        "disp = disp.plot(ax=ax)\n",
        "plt.grid(None)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R6zkLHWfChis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xLb485z5YWZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metrics of Accuracy, Balanced Accuracy, Recall, and AUC_ROC seem promising for our model. However, as our data is imbalanced, accuracy alone cannot be relied upon, and it may give misleading results. In this case, Recall and AUC_ROC metrics indicate a good fit for our data, but Precision is relatively low. The confusion matrix shows the presence of false-positive cases, which affects the precision of the model. However, false negatives are low, which improves the recall metric.\n",
        "\n",
        "In conclusion, we successfully used the logistic regression algorithm to model attrition in the dataset. Nevertheless, there is still room for improvement. To improve the model, we tried various sampling methods and evaluated their corresponding results to find the optimum sampling technique for this problem. Yet our final model using Grid Search achieved decent Recall and AUC ROC scores, suggesting a good fit over the data."
      ],
      "metadata": {
        "id": "4qIEleYePmtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "1. Data Preprocessing:\n",
        "\n",
        "\n",
        "\n",
        "* Data cleaning and handling missing values\n",
        "* Dropping irrelevant features\n",
        "* Encoding categorical features using LabelEncoder\n",
        "* Train-Test Split: Splitting the data into training and testing sets with a ratio of 80:20\n",
        "\n",
        "2. Sampling:\n",
        "\n",
        "Handling class imbalance by oversampling the minority class using SMOTE\n",
        "Feature Engineering:\n",
        "\n",
        "3. Scaling the features using StandardScaler\n",
        "Feature selection using Recursive Feature Elimination (RFE)\n",
        "Building the binary logistic regression model using the selected features\n",
        "Model Training:\n",
        "\n",
        "4. Fitting the binary logistic regression model on the training data\n",
        "Performance comparison between Train and Test:\n",
        "\n",
        "5. Evaluating the performance of the model on both the training and testing sets\n",
        "Cross-Validation:\n",
        "\n",
        "6. Applying 10-fold cross-validation to get a more reliable estimate of the model's performance\n",
        "\n",
        "7. Fine-tuning the model by tuning the hyperparameters using GridSearchCV\n",
        "Final Model:\n",
        "\n",
        "8. Building the final binary logistic regression model with the best hyperparameters\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ls9jFy6ReEAq"
      }
    }
  ]
}